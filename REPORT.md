# Report

## Failure points

### No messages received from kafka

Warning issued, program continues running

### DB write fails (network/server error)

Logs will continue to be stored in temporary files until they can be successfully written.
Only after that will they be deleted.

## Limitations

### Lost data

If the application can pick up the record from Kafka, the only way that it can get lost at that point is if the process is killed
and the record was not written to the temporary file/database yet. Opportunities for data loss are minimal.

### Duplicate data

Duplicate data will be stored if and only if a message is consumed multiple times from Kafka. To prevent this, messages must be purged from Kafka 
before restarting the program. It is practically impossible to prevent duplicates as the data itself has no builtin unique identifier.

### Latency

TODO benchmark how long between consume and write end

## Table architecture efficiency

### SIDENOTE

Depending on our expected dataset, the totals for any combination of the four parameters could be high, in which case it makes perfect sense to pre-compute them,
or they could be in the majority of cases close to 1, in which case the table holding these totals will be very large, and at that point it could make sense
to sacrifice some query speed to save on a significant amount of disk space. The decision in our architecture is to pre-compute all results though.

### Speed

The amount of rows that a table containing all totals grouped by a subset of the four specified parameters X is evidently 
`SELECT count(DISTINCT X) FROM http_log`.
Our implementation will always scan exactly this number of rows before returning. Considering our use case, it could be beneficial to also have these totals
pre-ordered, in order to quickly return for example the most frequently requested resources. This could likely be done using multiple tables and materialized
views, however this approach would lose the simplicity of a naturally formulated SELECT from a single table, and also materialized views don't seem as well 
behaved in maintaining the desired efficiency after repeated inserts. 

### Disk space

Using the sample data generated by the provided testing environment, the projections all take up about the same amount of space as is taken up by all of the 
logs on their own. This factor would probably be smaller with real data, because traffic would not be distributed evenly across all resource_ids.
One log appears to take up about 1 KiB of space in the table itself, and another KiB for the projection. At an average incoming message rate of 1000 per minute,
we would need about 2MiB per minute or about 3GB per day.
